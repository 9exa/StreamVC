""" StreamVC training script.
TODO: Complete after we decide where we keep the output model.

Example usage:
    python train.py --ce_lr=0.0001
"""
import argparse

from datasets import load_dataset
from datasets.iterable_dataset import IterableDataset
import torch
import torch.nn as nn
import torchaudio.transforms as T
from typing import Optional
import ssl
import numpy as np
import torch.optim as optim
from streamvc.model import StreamVC
from streamvc.train.encoder_classifier import EncoderClassifier

DATASET_SAMPLE_RATE = 24000
SAMPLE_RATE = 16000
NUM_CLASSES = 100
# TODO: Change batch size to 128 if we manage to run it faster.
BATCH_SIZE = 4
EMBEDDING_DIMS = 64
BETAS = (0.9, 0.98)
EPS = 1e-06
WEIGHT_DECAY = 1e-2
DATASET_PATH = "blabble-io/libritts"
# TODO: Change to 500.
TRAIN_SPLIT = "train.clean.100"
TEST_SPLIT = "test.clean"
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


def concat_and_pad_tensors(tensors: list[torch.Tensor]) -> torch.Tensor:
    """
    Concatenate tensors with variable length by padding with zeros at the end.
    :param tensors: A list of 1 dimension tensors.
    :return: A tensor of the concatenated input tensors padded with zeros at the end to match the length of the largest
             input tensor.
    Example:
      Input: list([1],
                  [2, 3],
                  [4, 5, 6])
      Output: torch.Tensor([[1, 0, 0],
                            [2, 3, 0],
                            [4, 5, 6]])
    """
    max_len = max([tensor.shape[0] for tensor in tensors])
    padded_vectors = [nn.functional.pad(vec, (0, max_len - vec.shape[0]), mode='constant', value=0) for vec in tensors]
    concatenated_vectors = torch.stack(padded_vectors, dim=0)
    return concatenated_vectors


def get_first_batch(batch_size: int) -> Optional[torch.Tensor]:
    # TODO: Delete if we don't use.
    """
    Returns the first batch from LibriTTS.

    :param batch_size: The batch size.
    :return: The first batch from LibriTTS.
    """
    data_iter = iter(load_dataset("blabble-io/libritts", "clean", split="train.clean.100", streaming=True))
    resampler = T.Resample(DATASET_SAMPLE_RATE, SAMPLE_RATE)
    resampler.to(torch.float32)
    samples = []
    for _ in range(batch_size):
        try:
            sample = next(data_iter)
            audio = torch.from_numpy(sample["audio"]["array"].astype(np.float32))
            resampled_audio = resampler(audio)
            samples.append(resampled_audio)
        except StopIteration:
            return None
    return concat_and_pad_tensors(samples)


def batch_generator(iterable_dataset: IterableDataset, batch_size: int) -> Optional[torch.Tensor]:
    """
    Generates the next batch from LibriTTS.

    :param iterable_dataset: Iterable dataset of type datasets.iterable_dataset.IterableDataset.
    :param batch_size: The batch size.
    :return: The next batch from LibriTTS.
    """
    resampler = T.Resample(DATASET_SAMPLE_RATE, SAMPLE_RATE)
    resampler.to(torch.float32)
    for batch in iterable_dataset.iter(batch_size=batch_size):
        audios_data = batch["audio"]
        audio_waveforms = [resampler(torch.from_numpy(audio_data["array"].astype(np.float32))) for audio_data in
                           audios_data]
        tensor_batch = concat_and_pad_tensors(audio_waveforms)
        yield tensor_batch


def streamvc_encoder_example(batch: Optional[torch.Tensor] = None):
    # TODO: Delete function when we finish with the training script.
    if batch is None:
        batch = get_first_batch(BATCH_SIZE)
    streamvc_model = StreamVC()
    content_encoder = streamvc_model.content_encoder
    print(f"{batch.shape=}")
    output = content_encoder(batch)
    print(f"{output.shape}")


def hubert_example(batch: Optional[torch.Tensor] = None):
    # TODO: Delete function when we finish with the training script.
    if batch is None:
        batch = get_first_batch(BATCH_SIZE)
    hubert = torch.hub.load("bshall/hubert:main", "hubert_discrete", trust_repo=True)
    simple_batch = batch[0].unsqueeze(0).unsqueeze(0)
    print(simple_batch.shape)
    units = hubert.units(simple_batch)
    print(units.shape)
    print(units)


@torch.no_grad()
def get_batch_labels(hubert_model: nn.Module, batch: torch.Tensor) -> torch.Tensor:
    """
    Get hubert output labels for a given audio samples batch.

    :param hubert_model: Hubert model with discrete output labels.
    :param batch: A batch of audio samples.
    :return: The output predictions generated by the Hubert model for the input batch.
    """
    labels = []
    for sample in batch:
        single_sample_batch = sample.unsqueeze(0).unsqueeze(0)
        labels.append(hubert_model.units(single_sample_batch))
    return torch.stack(labels, dim=0)


def train_content_encoder(content_encoder: nn.Module, hubert_model: nn.Module, lr: float, num_epochs: int) -> nn.Module:
    """
    Train a content encoder as a classifier to predict the same labels as a discrete hubert model.

    :param content_encoder: A content encoder wrapped with a linear layer to
    :param hubert_model: Hubert model with discrete output labels.
    :param lr: Learning rate.
    :param num_epochs: Number of epochs.
    :return: The trained content encoder wrapped with a linear layer for classification.
    """
    # TODO: add epochs or number of steps when we know how much time it takes to train the model.
    wrapped_content_encoder = EncoderClassifier(content_encoder, EMBEDDING_DIMS, NUM_CLASSES).to(DEVICE)
    criterion = nn.CrossEntropyLoss()
    # TODO: Consider using AdamW instead.
    optimizer = optim.AdamW(
        wrapped_content_encoder.parameters(),
        lr=lr,
        betas=BETAS,
        eps=EPS,
        weight_decay=WEIGHT_DECAY,
    )
    for epoch in range(1, num_epochs + 1):
        step = 0
        running_loss = 0.0
        running_loss_samples_num = 0
        dataset = load_dataset(DATASET_PATH, "all", split=TRAIN_SPLIT, streaming=True)
        for batch in batch_generator(dataset, BATCH_SIZE):
            batch = batch.to(DEVICE)
            step += 1
            optimizer.zero_grad()

            labels = get_batch_labels(hubert_model, batch)
            outputs = wrapped_content_encoder(batch)
            outputs_flat = outputs.view(-1, NUM_CLASSES)
            labels_flat = labels.view(-1)

            loss = criterion(outputs_flat, labels_flat)
            loss.backward()
            optimizer.step()

            running_loss += loss.item()
            running_loss_samples_num += labels_flat.shape[0]
            if step % 5 == 0:  # print every 5 mini-batches
                print('[%d, %5d] loss: %.4f' %
                      (epoch, step, running_loss / running_loss_samples_num))
                running_loss = 0.0
                running_loss_samples_num = 0
    return wrapped_content_encoder


def compute_accuracy(wrapped_content_encoder: nn.Module, hubert_model: nn.Module):
    correct = 0
    total = 0
    with torch.no_grad():
        dataset = load_dataset(DATASET_PATH, "clean", split=TEST_SPLIT, streaming=True)
        for batch in batch_generator(dataset, BATCH_SIZE):
            labels = get_batch_labels(hubert_model, batch)
            outputs = wrapped_content_encoder(batch)
            outputs_flat = outputs.view(-1, NUM_CLASSES)
            labels_flat = labels.view(-1)
            _, predicted = torch.max(outputs_flat.data, 1)
            total += labels_flat.size(0)
            correct += (predicted == labels_flat).sum().item()

    print('Accuracy of the network: %d %%' % (
            100 * correct / total))


def main(args: argparse.Namespace, show_accuracy: bool = True) -> None:
    """Main function for training StreamVC model."""
    streamvc_model = StreamVC().to(DEVICE)
    content_encoder = streamvc_model.content_encoder
    hubert_model = torch.hub.load("bshall/hubert:main", "hubert_discrete", trust_repo=True) \
        .to(DEVICE).eval()
    wrapped_content_encoder = train_content_encoder(content_encoder, hubert_model, args.ce_lr, args.ce_epochs)
    if show_accuracy:
        compute_accuracy(wrapped_content_encoder, hubert_model)
    # TODO: Train `streamvc_model`.


if __name__ == '__main__':
    ssl._create_default_https_context = ssl._create_unverified_context

    parser = argparse.ArgumentParser(
        prog='StreamVC Training Script',
        description='Training script for StreamVC model, using the LibriTTS dataset')
    parser.add_argument("--ce_lr", type=float, default=0.005,
                        help="Learning rate for content encoder training.")
    parser.add_argument("--ce_epochs", type=int, default=1,
                        help="Number of epochs for content encoder training.")
    args = parser.parse_args()

    main(args)
