from itertools import islice
import torch
import torch.nn as nn
import torch.optim as optim
from streamvc.model import StreamVC
from streamvc.train.encoder_classifier import EncoderClassifier
from streamvc.train.libritts import get_libritts_dataloader
import time
from accelerate import Accelerator
import os

accelerator = Accelerator()
torch.backends.cudnn.benchmark = True
torch.backends.cudnn.enabled = True

SAMPLE_RATE = 16000
NUM_CLASSES = 100
# TODO: Change batch size to 128 if we manage to run it faster.
BATCH_SIZE = 8
NUM_EPOCHS = 1
EMBEDDING_DIMS = 64
BETAS = (0.9, 0.98)
EPS = 1e-06
WEIGHT_DECAY = 1e-2
DATASET_PATH = "blabble-io/libritts"
# TODO: Change to 500.
TRAIN_SPLIT = "train.clean.100"
TEST_SPLIT = "test.clean"
DEVICE = accelerator.device

DTYPE = torch.float32

if isinstance(accelerator.mixed_precision, str):
    if accelerator.mixed_precision == "fp16":
        DTYPE = torch.float16
    elif accelerator.mixed_precision == "bf16":
        DTYPE = torch.bfloat16

CHECKPOINTS_PATH = os.environ.get(
    "CHECKPOINTS_PATH", os.path.join(os.getcwd(), "checkpoints"))


def print_time(s):
    t = time.localtime()
    current_time = time.strftime("%H:%M:%S", t)
    accelerator.print(f"[{current_time}] - {s}", flush=True)


def sizeof_fmt(num, suffix="B"):
    for unit in ("", "K", "M", "G", "T", "P"):
        if abs(num) < 1024.0:
            return f"{num:4.1f} {unit}{suffix}"
        num /= 1024.0


def print_cuda_memory(s):
    free, total = torch.cuda.mem_get_info()
    curr = torch.cuda.memory_allocated()
    peak = torch.cuda.max_memory_allocated()

    accelerator.print(
        f"{{alloc {sizeof_fmt(curr)} | tot {sizeof_fmt(total)} | free {sizeof_fmt(free)} | peak {sizeof_fmt(peak)}}} - {s}", flush=True)


@torch.no_grad()
def get_batch_labels(hubert_model: nn.Module, batch: torch.Tensor) -> torch.Tensor:
    """
    Get hubert output labels for a given audio samples batch.

    :param hubert_model: Hubert model with discrete output labels.
    :param batch: A batch of audio samples.
    :return: The output predictions generated by the Hubert model for the input batch.
    """
    labels = []
    for sample in batch:
        sample = sample.to(device='cpu', dtype=torch.float32)
        single_sample_batch = sample.unsqueeze(0).unsqueeze(0)
        labels.append(hubert_model.units(single_sample_batch))
    return torch.stack(labels, dim=0).to(device=DEVICE)


def train_content_encoder(content_encoder: nn.Module, hubert_model: nn.Module, lr: float) -> nn.Module:
    """
    Train a content encoder as a classifier to predict the same labels as a discrete hubert model.

    :param content_encoder: A content encoder wrapped with a linear layer to
    :param hubert_model: Hubert model with discrete output labels.
    :param lr: Learning rate.
    :param num_epochs: Number of epochs.
    :return: The trained content encoder wrapped with a linear layer for classification.
    """
    # TODO: add epochs or number of steps when we know how much time it takes to train the model.
    wrapped_content_encoder = EncoderClassifier(
        content_encoder, EMBEDDING_DIMS, NUM_CLASSES).to(device=DEVICE, dtype=DTYPE)
    print_cuda_memory("classifier")
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(
        wrapped_content_encoder.parameters(),
        lr=lr,
        betas=BETAS,
        eps=EPS,
        weight_decay=WEIGHT_DECAY,
    )
    dataloader = get_libritts_dataloader(TRAIN_SPLIT, BATCH_SIZE)

    wrapped_content_encoder, optimizer, dataloader = accelerator.prepare(
        wrapped_content_encoder, optimizer, dataloader
    )

    print_cuda_memory("accelerator")

    for epoch in range(0, NUM_EPOCHS):
        print_time(f"start epoch {epoch}")
        running_loss = 0.0
        running_loss_samples_num = 0
        for step, batch in enumerate(islice(dataloader, 5)):
            optimizer.zero_grad()
            print_cuda_memory("batch")
            labels = get_batch_labels(hubert_model, batch)
            print_cuda_memory("labels")
            with accelerator.autocast():
                outputs = wrapped_content_encoder(batch)
                print_cuda_memory("forward")
                outputs_flat = outputs.view(-1, NUM_CLASSES)
                labels_flat = labels.view(-1)

                loss = criterion(outputs_flat, labels_flat)
                print_cuda_memory("loss")
                accelerator.backward(loss)
                print_cuda_memory("backward")
                optimizer.step()
                print_cuda_memory("step")

            running_loss += loss.item()
            running_loss_samples_num += labels_flat.shape[0]
            # if step % 20 == 0:
            print_time(
                f'[{epoch}, {step:5}] loss: {running_loss / running_loss_samples_num:.4}')
            running_loss = 0.0
            running_loss_samples_num = 0

    return wrapped_content_encoder


@ torch.no_grad()
def compute_content_encoder_accuracy(wrapped_content_encoder: nn.Module, hubert_model: nn.Module):
    correct = 0
    total = 0
    dataloader = get_libritts_dataloader(TEST_SPLIT, BATCH_SIZE)
    wrapped_content_encoder.eval()
    print_cuda_memory("accuracy")
    for batch in islice(dataloader, 5):
        batch = batch.to(device=DEVICE)
        print_cuda_memory("batch")
        labels = get_batch_labels(hubert_model, batch)
        print_cuda_memory("labels")
        outputs = wrapped_content_encoder(batch)
        print_cuda_memory("forward")
        outputs_flat = outputs.view(-1, NUM_CLASSES)
        labels_flat = labels.view(-1)
        _, predicted = torch.max(outputs_flat.data, 1)
        total += labels_flat.size(0)
        correct += (predicted == labels_flat).sum().item()

    wrapped_content_encoder.train()

    print_time('Accuracy of the network: %d %%' % (
        100 * correct / total))


def main():
    """Main function for training StreamVC model."""
    print_time(f"{DEVICE=} {DTYPE=} {CHECKPOINTS_PATH=}")
    streamvc = StreamVC()
    torch.cuda.memory._record_memory_history()
    print_cuda_memory("start")
    content_encoder = streamvc.content_encoder.to(
        device=DEVICE, dtype=DTYPE).train()
    print_cuda_memory("encoder")
    hubert_model = torch.hub.load("bshall/hubert:main", "hubert_discrete",
                                  trust_repo=True).to(torch.float32).eval()
    wrapped_content_encoder = train_content_encoder(
        content_encoder, hubert_model, 0.005)
    torch.cuda.memory._dump_snapshot(
        os.path.join(CHECKPOINTS_PATH, "snapshot4.pickle"))
    # accelerator.save_state(CHECKPOINTS_PATH)
    compute_content_encoder_accuracy(wrapped_content_encoder, hubert_model)


if __name__ == '__main__':
    main()
